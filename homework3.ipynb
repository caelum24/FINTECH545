{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from numpy.linalg import cholesky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_matrix_correctness(input_matrix, test_matrix, error_epsilon = 1e-12):\n",
    "\n",
    "    input_matrix = np.asarray(input_matrix)\n",
    "    test_matrix = np.asarray(test_matrix)\n",
    "    assert input_matrix.shape == test_matrix.shape, \"Input matrix and test matrix have different shapes\"\n",
    "    for i in range(input_matrix.shape[0]):\n",
    "        for j in range(input_matrix.shape[1]):\n",
    "            assert abs(input_matrix[i,j] - test_matrix[i,j]) < error_epsilon, f\"row {i} and column {j} of the data do not match\"\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5.1 Normal Simulation PD Input 0 mean - 100,000 simulations, compare input vs output covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5_1 = pd.read_csv(\"testfiles/data/test5_1.csv\")\n",
    "\n",
    "def normal_monte_carlo_simulation(mean_vector, covariance_matrix, n_sims, fix_method, seed=1234):\n",
    "\n",
    "    np.random.seed(seed=seed)\n",
    "\n",
    "    # check for positive-semidefiniteness\n",
    "    eigvals = np.linalg.eigvalsh(covariance_matrix)\n",
    "    if np.any(eigvals < 0):\n",
    "        # if not positive-semidefinite, use fix_method to fix\n",
    "        input_cov = covariance_matrix\n",
    "        covariance_matrix = fix_method(input_cov)\n",
    "\n",
    "    simulation_data = np.random.multivariate_normal(mean_vector, covariance_matrix, n_sims).T # len(cov), n\n",
    "    sim_cov = np.cov(simulation_data, bias=False)\n",
    "    \n",
    "    return sim_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance_matrix = data_5_1\n",
    "mean_vector = np.zeros(shape=(len(covariance_matrix)))\n",
    "n_sims = 100_000\n",
    "sim_cov = normal_monte_carlo_simulation(mean_vector, covariance_matrix, n_sims = n_sims, fix_method=lambda x: x, seed=42)\n",
    "test_5_1 = pd.read_csv(\"testfiles/data/testout_5.1.csv\")\n",
    "check_matrix_correctness(sim_cov, test_5_1, error_epsilon=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5.2 Normal Simulation PSD Input 0 mean - 100,000 simulations, compare input vs output covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from covariance_comp import higham_covariance, near_psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5_2 = pd.read_csv(\"testfiles/data/test5_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance_matrix = data_5_2\n",
    "mean_vector = np.zeros(shape=(len(covariance_matrix)))\n",
    "n_sims = 100_000\n",
    "sim_cov = normal_monte_carlo_simulation(mean_vector, covariance_matrix, n_sims = n_sims, fix_method=near_psd)\n",
    "test_5_2 = pd.read_csv(\"testfiles/data/testout_5.2.csv\")\n",
    "check_matrix_correctness(sim_cov, test_5_2, error_epsilon=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5.3 Normal Simulation nonPSD Input, 0 mean, near_psd fix - 100,000 simulations, compare input vs output covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_5_3 = pd.read_csv(\"testfiles/data/test5_3.csv\")\n",
    "covariance_matrix = data_5_3\n",
    "mean_vector = np.zeros(shape=(len(covariance_matrix)))\n",
    "n_sims = 100_000\n",
    "sim_cov = normal_monte_carlo_simulation(mean_vector, covariance_matrix, n_sims = n_sims, fix_method=near_psd)\n",
    "test_5_3 = pd.read_csv(\"testfiles/data/testout_5.3.csv\")\n",
    "check_matrix_correctness(sim_cov, test_5_3, error_epsilon=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5.4 Normal Simulation PSD Input, 0 mean, higham fix - 100,000 simulations, compare input vs output covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_5_4 = pd.read_csv(\"testfiles/data/test5_3.csv\")\n",
    "covariance_matrix = data_5_4\n",
    "mean_vector = np.zeros(shape=(len(covariance_matrix)))\n",
    "n_sims = 100_000\n",
    "sim_cov = normal_monte_carlo_simulation(mean_vector, covariance_matrix, n_sims = n_sims, fix_method=higham_covariance)\n",
    "test_5_4 = pd.read_csv(\"testfiles/data/testout_5.4.csv\")\n",
    "check_matrix_correctness(sim_cov, test_5_4, error_epsilon=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5.5 PCA Simulation, 99% explained, 0 mean - 100,000 simulations compare input vs output covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vector = np.zeros(shape=len(data_5_2))\n",
    "\n",
    "data_5_5 = pd.read_csv(\"testfiles/data/test5_2.csv\")\n",
    "covariance_matrix = data_5_2\n",
    "def pca_monte_carlo_simulation(mean_vector, covariance_matrix, n_sims, explained_threshold = 0.99, seed=1234):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    eigvals, eigvecs = np.linalg.eigh(covariance_matrix)\n",
    "    eigvals = np.clip(eigvals, 0, None)\n",
    "    idx = np.argsort(eigvals)[::-1]\n",
    "    eigvals = eigvals[idx]\n",
    "    eigvecs = eigvecs[:, idx]\n",
    "\n",
    "    k = len(eigvals)\n",
    "    pct_explained = eigvals[:k-1].sum() / eigvals.sum()\n",
    "    while pct_explained > explained_threshold:\n",
    "        k -= 1\n",
    "        pct_explained = eigvals[:k-1].sum() / eigvals.sum()\n",
    "\n",
    "    L = eigvecs[:,:k] @ np.diag(np.sqrt(eigvals[:k]))\n",
    "    simulation_data = np.random.multivariate_normal(np.zeros(k), np.identity(k), n_sims).T # len(cov), n\n",
    "    transformed_data = L @ simulation_data + mean_vector[:,np.newaxis]\n",
    "\n",
    "    sim_cov = np.cov(transformed_data, bias=False)\n",
    "\n",
    "    return sim_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_5_5 = pd.read_csv(\"testfiles/data/test5_2.csv\")\n",
    "covariance_matrix = data_5_2\n",
    "mean_vector = np.zeros(shape=len(covariance_matrix))\n",
    "n_sims = 100_000\n",
    "sim_cov = pca_monte_carlo_simulation(mean_vector, covariance_matrix, n_sims, explained_threshold = 0.99, seed=42)\n",
    "test_5_5 = pd.read_csv(\"testfiles/data/testout_5.5.csv\")\n",
    "check_matrix_correctness(sim_cov, test_5_5, error_epsilon=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 8.1 Normal VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_8_1 = pd.read_csv(\"testfiles/data/test7_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function from homework 1\n",
    "def fit_normal_dist_from_data(x: pd.DataFrame):\n",
    "    mu_vector = x.mean()\n",
    "    covariance_matrix = x.cov()\n",
    "\n",
    "    return mu_vector, covariance_matrix\n",
    "\n",
    "mu_vector, covariance_matrix = fit_normal_dist_from_data(data_8_1)\n",
    "mean, std = mu_vector.iloc[0], np.sqrt(covariance_matrix.iloc[0,0])\n",
    "\n",
    "\n",
    "def univariate_normal_VaR(x: pd.DataFrame, alpha = 0.05):\n",
    "    mu_vector, covariance_matrix = fit_normal_dist_from_data(x)\n",
    "    mean, std = mu_vector.iloc[0], np.sqrt(covariance_matrix.iloc[0,0])\n",
    "\n",
    "    abs_VaR = -norm.ppf(alpha, loc = mean, scale = std)\n",
    "    rel_VaR = mean - norm.ppf(alpha, loc = mean, scale = std)\n",
    "\n",
    "    return abs_VaR, rel_VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_VaR, rel_VaR = univariate_normal_VaR(data_8_1, alpha = 0.05)\n",
    "test_8_1 = pd.read_csv(\"testfiles/data/testout8_1.csv\")\n",
    "error_epsilon =1e-12\n",
    "assert \tabs(abs_VaR - test_8_1.loc[0, \"VaR Absolute\"]) < error_epsilon, \"Absolute value at risk does not match\"\n",
    "assert \tabs(rel_VaR - test_8_1.loc[0, \"VaR Diff from Mean\"]) < error_epsilon, \"Absolute value at risk does not match\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 8.2 VaR T Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_8_2 = pd.read_csv(\"testfiles/data/test7_2.csv\")\n",
    "\n",
    "# function from homework 1\n",
    "from scipy.stats import t\n",
    "nu, mu, sigma = t.fit(data_8_2)\n",
    "mu, sigma, nu\n",
    "alpha = 0.05\n",
    "# print(t.ppf(alpha, df = nu, loc = mu, scale = sigma))\n",
    "\n",
    "def univariate_t_VaR(x: pd.DataFrame, alpha = 0.05):\n",
    "    nu, mu, sigma = t.fit(x)\n",
    "\n",
    "    abs_VaR = -t.ppf(alpha, df = nu, loc = mu, scale = sigma)\n",
    "    rel_VaR = mu - t.ppf(alpha, df = nu, loc = mu, scale = sigma)\n",
    "        \n",
    "    return abs_VaR, rel_VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_8_2 = pd.read_csv(\"testfiles/data/test7_2.csv\")\n",
    "abs_VaR, rel_VaR = univariate_t_VaR(data_8_2, alpha = 0.05)\n",
    "\n",
    "test_8_2 = pd.read_csv(\"testfiles/data/testout8_2.csv\")\n",
    "error_epsilon = 1e-7\n",
    "assert \tabs(abs_VaR - test_8_2.loc[0, \"VaR Absolute\"]) < error_epsilon, \"Absolute value at risk does not match\"\n",
    "assert \tabs(rel_VaR - test_8_2.loc[0, \"VaR Diff from Mean\"]) < error_epsilon, \"Absolute value at risk does not match\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 8.3 VaR from Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_8_3 = pd.read_csv(\"testfiles/data/test7_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_VaR_sim(mean_vector, covariance_matrix, current_prices, holdings, n_draws, return_type = \"arithmetic\", alpha = 0.05, seed = 1234):\n",
    "\n",
    "    if return_type not in [\"arithmetic\", \"geometric\", \"brownian\"]:\n",
    "        raise ValueError(\"Returns must be one of arithmetic, geometric, brownian\")\n",
    "\n",
    "    if covariance_matrix.shape[0] != covariance_matrix.shape[1]:\n",
    "        raise ValueError(\"Covariance matrix must be square\")\n",
    "        \n",
    "    if len(mean_vector) != covariance_matrix.shape[0]:\n",
    "        raise ValueError(\"Mean matrix length must match Covariance matrix dimensions\")\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    portfolio_value = current_prices.dot(holdings)\n",
    "\n",
    "    simulated_returns = rng.multivariate_normal(mean_vector, covariance_matrix, n_draws)\n",
    "    # simulated_returns = np.random.normal(mean_vector.iloc[0], np.sqrt(cov.iloc[0,0]), size = n_draws)[:, np.newaxis]\n",
    "\n",
    "    if return_type == \"arithmetic\":\n",
    "        simulated_prices = (1 + simulated_returns) * current_prices\n",
    "    elif return_type == \"geometric\":\n",
    "        simulated_prices = current_prices * np.exp(simulated_returns)\n",
    "    elif return_type == \"brownian\":\n",
    "        simulated_prices = current_prices + simulated_returns\n",
    "\n",
    "    sim_portfolio_values = simulated_prices.dot(holdings)\n",
    "    sorted_values = np.sort(sim_portfolio_values)\n",
    "\n",
    "    percentile_portfolio = np.percentile(sim_portfolio_values, 100 * alpha)\n",
    "    abs_VaR = portfolio_value - percentile_portfolio\n",
    "    rel_VaR = np.mean(sim_portfolio_values) - percentile_portfolio\n",
    "    return abs_VaR, rel_VaR\n",
    "\n",
    "# nu, mu, sigma = t.fit(data_8_3)\n",
    "# random_returns = t.rvs(df=nu, loc=mu, scale=sigma, size=n_draws, random_state=seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mu, cov = fit_normal_dist_from_data(data_8_3)\n",
    "mean_vector = mu\n",
    "current_prices=np.array([1])\n",
    "holdings = np.array([1])\n",
    "# cov = np.array([[sigma**2]])\n",
    "abs_VaR, rel_VaR = monte_carlo_VaR_sim(mean_vector=mean_vector, covariance_matrix = cov, current_prices=current_prices, holdings=holdings, n_draws=100_000, return_type = \"arithmetic\", alpha = 0.05, seed = 42)\n",
    "\n",
    "test_8_3 = pd.read_csv(\"testfiles/data/testout8_3.csv\")\n",
    "error_epsilon = 1e-2 # NOTE this simulation only gets somewhat close even when doing 100M simulations, but the implementation seems correct\n",
    "assert \tabs(abs_VaR - test_8_3.loc[0, \"VaR Absolute\"]) < error_epsilon, \"Absolute value at risk does not match\"\n",
    "assert \tabs(rel_VaR - test_8_3.loc[0, \"VaR Diff from Mean\"]) < error_epsilon, \"Absolute value at risk does not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "536fca8a70b20dc309c68387fb4322ec0bd98e3a90262e6704560667c02e5263"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
